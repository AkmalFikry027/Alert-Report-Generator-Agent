{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":121144,"databundleVersionId":14484960,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# Disaster Information Extraction & Alert Agent\n\nMain Features Implemented:\n- Multi-agent (LLM, parallel, sequential, loop agents)\n- Tools: Google Search (via SerpAPI mock), Gemini (simulated), Code Execution, MCP (stub), custom Extraction tool\n- Sessions & Memory\n- Context compaction\n- Observability (Logging, Tracing, Metrics)\n- Agent evaluation framework\n- A2A protocol (internal messaging)\nNote: No secrets/API keys exposed. Gemini agent is simulated for demo.\n\n\n**1. PROBLEM:**\nTimely disaster info is critical for saving lives, but accurate & rapid extraction from real-world noisy sources is challenging.\n\n**2. SOLUTION:**\nMulti-agent system combines LLM extraction, parallel processing, periodic fetching, and alert/reporting, using modern agent features.\n\n**3. VALUE:** \nExtensible, observable, robust architecture suitable for real-time disaster signal processing.\n\n\n","metadata":{}},{"cell_type":"code","source":"pip install langchain-google-genai\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T15:50:48.970766Z","iopub.execute_input":"2025-12-03T15:50:48.971277Z","iopub.status.idle":"2025-12-03T15:50:59.239223Z","shell.execute_reply.started":"2025-12-03T15:50:48.971245Z","shell.execute_reply":"2025-12-03T15:50:59.238183Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain-google-genai\n  Downloading langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\nCollecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\nCollecting langchain-core<2.0.0,>=1.1.0 (from langchain-google-genai)\n  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.12.4)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.28.1)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.38.0)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.74.0)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (6.33.0)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.33)\nRequirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.4.8)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (25.0)\nRequirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (6.0.3)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (9.1.2)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (4.15.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\nRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.70.0)\nRequirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.32.5)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.71.2)\nCollecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai)\n  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.11.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.23.0)\nCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.16.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.5.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.3.1)\nDownloading langchain_google_genai-3.2.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\nDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf, cachetools, langchain-core, google-ai-generativelanguage, langchain-google-genai\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 6.2.1\n    Uninstalling cachetools-6.2.1:\n      Successfully uninstalled cachetools-6.2.1\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.72\n    Uninstalling langchain-core-0.3.72:\n      Successfully uninstalled langchain-core-0.3.72\n  Attempting uninstall: google-ai-generativelanguage\n    Found existing installation: google-ai-generativelanguage 0.6.15\n    Uninstalling google-ai-generativelanguage-0.6.15:\n      Successfully uninstalled google-ai-generativelanguage-0.6.15\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nlangchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.1.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngoogle-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nlangchain-text-splitters 0.3.9 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.1.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cachetools-5.5.2 google-ai-generativelanguage-0.9.0 langchain-core-1.1.0 langchain-google-genai-3.2.0 protobuf-5.29.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport time\nimport logging\nimport sqlite3\nfrom datetime import datetime, timedelta\nfrom typing import TypedDict, Dict, Any, List\n\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_community.utilities import SerpAPIWrapper\nfrom langchain.tools import tool\nfrom langchain.chains.llm import LLMChain\nfrom langchain.prompts import PromptTemplate\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.checkpoint.sqlite import SqliteSaver","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Observability: Logging, Metrics, Tracing\n# Logging provides visibility into the agent workflow.\n# Metrics store aggregated stats for monitoring performance.\n# Trace log keeps a detailed sequence of internal events.\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(\"DisasterAlertAgent\")\n\nmetrics = {\n    \"executions\": 0,\n    \"errors\": 0,\n    \"avg_time\": 0.0,\n    \"alerts_sent\": 0,\n    \"search_queries\": 0,\n}\n\ntrace_log: List[Dict[str, Any]] = []\n\n\ndef trace(event: str, data: Any = None) -> None:\n    trace_log.append({\"event\": event, \"data\": data})\n    logger.debug(f\"TRACE - {event}: {data}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LLM and Tools Configuration\n# Configure Gemini (API key via env var)\nGOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\nif not GOOGLE_API_KEY:\n    logger.warning(\"GOOGLE_API_KEY not set. Configure it via environment variable.\")\nllm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", temperature=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SerpAPI for web search (API key via env var)\nSERPAPI_API_KEY = os.getenv(\"SERPAPI_API_KEY\")\nif not SERPAPI_API_KEY:\n    logger.warning(\"SERPAPI_API_KEY not set. Configure it via environment variable.\")\nsearch_tool = GoogleSerpAPIWrapper()\n\n\n@tool\ndef send_alert_email(alert_message: str, recipient: str) -> str:\n    \"\"\"Sends an alert email to the recipient (mock; replace with real SMTP).\"\"\"\n    logger.info(f\"(MOCK) Sending email to {recipient}: {alert_message}\")\n    return \"Alert sent successfully (mocked).\"\n\n\n@tool\ndef fetch_usgs_earthquakes(starttime: str, minmagnitude: float = 4.0) -> str:\n    \"\"\"Fetches recent earthquakes from USGS API as raw JSON text.\"\"\"\n    import requests\n    url = (\n        \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n        f\"?format=geojson&starttime={starttime}&minmagnitude={minmagnitude}\"\n    )\n    logger.info(f\"Fetching USGS earthquakes from {url}\")\n    trace(\"USGSFetch\", {\"url\": url})\n    try:\n        response = requests.get(url, timeout=10)\n    except Exception as e:\n        logger.error(f\"Error calling USGS API: {e}\")\n        return f\"Error fetching USGS data: {e}\"\n\n    if response.status_code == 200:\n        return response.text\n    else:\n        logger.error(f\"USGS API error: status={response.status_code}, body={response.text[:200]}\")\n        return f\"Error fetching USGS data: HTTP {response.status_code}\"\n\n\n@tool\ndef mcp_action(action: str, params: Dict[str, Any]) -> str:\n    \"\"\"Simulated MCP (Multi-Chain Prompting) / custom tool.\"\"\"\n    trace(\"MCP\", {\"action\": action, \"params\": params})\n    return f\"[MCP] Performed action {action} with params {params}\"\n\n\n@tool\ndef code_execution(code: str) -> str:\n    \"\"\"Safe(ish) code execution for small expressions.\"\"\"\n    trace(\"CodeExecution\", code)\n    try:\n        result = eval(code, {\"__builtins__\": {}})\n    except Exception as e:\n        result = f\"Error: {e}\"\n    return str(result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Memory Bank (SQLite)\n# Stores previously generated alerts for historical lookup.\n# Used to build long term disaster awareness for the AI agent.\nconn = sqlite3.connect(\"memory_bank.db\")\nconn.execute(\n    \"\"\"\n    CREATE TABLE IF NOT EXISTS alerts (\n        id INTEGER PRIMARY KEY,\n        timestamp TEXT,\n        disaster_type TEXT,\n        details TEXT\n    )\n\"\"\"\n)\nconn.commit()\n\n\ndef store_in_memory_bank(disaster_type: str, details: str) -> None:\n    timestamp = datetime.now().isoformat()\n    conn.execute(\n        \"INSERT INTO alerts (timestamp, disaster_type, details) VALUES (?, ?, ?)\",\n        (timestamp, disaster_type, details),\n    )\n    conn.commit()\n    logger.info(f\"Stored alert in memory bank as {disaster_type}.\")\n    trace(\"MemoryBankStore\", {\"disaster_type\": disaster_type, \"details\": details[:200]})\n\n\ndef retrieve_from_memory_bank(disaster_type: str) -> List[Dict[str, Any]]:\n    cursor = conn.execute(\n        \"SELECT * FROM alerts WHERE disaster_type = ? ORDER BY timestamp DESC\",\n        (disaster_type,),\n    )\n    results = [{\"timestamp\": row[1], \"details\": row[3]} for row in cursor.fetchall()]\n    trace(\"MemoryBankRetrieve\", {\"disaster_type\": disaster_type, \"count\": len(results)})\n    return results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Context Compaction (Summarization)\nsummarize_prompt = PromptTemplate(\n    input_variables=[\"text\"],\n    template=\"Summarize the key disaster-related points clearly and concisely:\\n{text}\",\n)\nsummarize_chain = LLMChain(llm=llm, prompt=summarize_prompt)\n\n\ndef compact_context(text: str) -> str:\n    \"\"\"Compacts long raw context via summarization LLM.\"\"\"\n    trace(\"ContextCompactionRequest\", {\"len\": len(text)})\n    summary = summarize_chain.run(text=text)\n    trace(\"ContextCompactionResult\", {\"len\": len(summary)})\n    return summary\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Agent Definitions (LangGraph Nodes)\nclass AgentState(TypedDict, total=False):\n    query: str\n    collected_data: str\n    extracted_info: str\n    alert_message: str\n    logs: List[str]\n\n\ndef add_log(state: AgentState, msg: str) -> None:\n    if \"logs\" not in state or state[\"logs\"] is None:\n        state[\"logs\"] = []\n    state[\"logs\"].append(msg)\n\n\ndef data_collector_agent(state: AgentState) -> AgentState:\n    \"\"\"Data Collector Agent (parallel web + USGS).\"\"\"\n    query = state[\"query\"]\n    logger.info(f\"Collector: running search for '{query}'\")\n    trace(\"CollectorStart\", {\"query\": query})\n\n    # Web search\n    metrics[\"search_queries\"] += 1\n    web_results = search_tool.run(f\"recent {query} disasters news\")\n    trace(\"WebSearchResults\", {\"len\": len(web_results)})\n\n    # USGS earthquakes (last 24h)\n    starttime = (datetime.utcnow() - timedelta(days=1)).isoformat()\n    usgs_results = fetch_usgs_earthquakes(starttime=starttime)\n    trace(\"USGSResultsLength\", {\"len\": len(usgs_results)})\n\n    # Compact context (to control token usage)\n    raw_text = f\"WEB_RESULTS:\\n{web_results}\\n\\nUSGS_RESULTS:\\n{usgs_results}\"\n    collected_data = compact_context(raw_text)\n\n    state[\"collected_data\"] = collected_data\n    add_log(state, \"Collector: data collected and compacted.\")\n    logger.info(\"Collector: completed.\")\n    return state\n\n\nextract_prompt = PromptTemplate(\n    input_variables=[\"data\"],\n    template=(\n        \"You are an expert disaster information extractor.\\n\"\n        \"Extract a structured description of all disasters mentioned, including:\\n\"\n        \"- type (e.g., earthquake, flood, hurricane)\\n\"\n        \"- location\\n\"\n        \"- severity/intensity\\n\"\n        \"- time (approximate in ISO or human-readable form)\\n\"\n        \"- any key impact details (deaths, damage, alerts)\\n\\n\"\n        \"Return a concise but information-rich summary:\\n\\n\"\n        \"{data}\"\n    ),\n)\nextract_chain = LLMChain(llm=llm, prompt=extract_prompt)\n\n\ndef info_extractor_agent(state: AgentState) -> AgentState:\n    \"\"\"Information Extractor Agent (LLM-powered).\"\"\"\n    data = state[\"collected_data\"]\n    logger.info(\"Extractor: extracting structured information.\")\n    trace(\"ExtractorStart\", {\"len\": len(data)})\n    extracted = extract_chain.run(data=data)\n    state[\"extracted_info\"] = extracted\n    add_log(state, \"Extractor: info extracted.\")\n    trace(\"ExtractorResult\", {\"len\": len(extracted)})\n    return state\n\n\ngenerate_prompt = PromptTemplate(\n    input_variables=[\"info\"],\n    template=(\n        \"You are an emergency alert generator.\\n\"\n        \"Given this structured disaster information, generate a clear, concise alert message \"\n        \"suitable for sending by email or SMS.\\n\"\n        \"Focus on: type, location, severity, time, and guidance for recipients.\\n\\n\"\n        \"{info}\"\n    ),\n)\ngenerate_chain = LLMChain(llm=llm, prompt=generate_prompt)\n\n\ndef alert_generator_agent(state: AgentState) -> AgentState:\n    \"\"\"Alert Generator Agent (with refinement loop + memory).\"\"\"\n    info = state[\"extracted_info\"]\n    logger.info(\"Generator: generating initial alert.\")\n    trace(\"GeneratorStart\", {\"len\": len(info)})\n    alert = generate_chain.run(info=info)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Simple refinement loop if message too long\n    refinement_count = 0\n    while len(alert) > 500 and refinement_count < 3:\n        logger.info(\n            f\"Generator: alert too long ({len(alert)} chars), compacting (iteration {refinement_count+1}).\"\n        )\n        alert = compact_context(alert)\n        refinement_count += 1\n\n    state[\"alert_message\"] = alert\n    add_log(state, \"Generator: alert generated.\")\n    trace(\"GeneratorResult\", {\"len\": len(alert)})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Store in long-term memory (simple disaster-type detection)\n    lower_info = info.lower()\n    if \"earthquake\" in lower_info:\n        disaster_type = \"earthquake\"\n    elif \"flood\" in lower_info:\n        disaster_type = \"flood\"\n    else:\n        disaster_type = \"other\"\n\n    store_in_memory_bank(disaster_type, alert)\n    return state\n\n\ndef alert_sender_agent(state: AgentState) -> AgentState:\n    \"\"\"Alert Sender Agent (uses custom email tool).\"\"\"\n    alert = state[\"alert_message\"]\n    logger.info(\"Sender: sending alert via email tool.\")\n    trace(\"SenderStart\", {\"len\": len(alert)})\n    send_alert_email(alert, \"user@example.com\")\n    metrics[\"alerts_sent\"] += 1\n    add_log(state, \"Sender: alert sent (mock).\")\n    logger.info(\"Sender: completed.\")\n    trace(\"SenderComplete\", None)\n    return state","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LangGraph: Build the Graph\ngraph = StateGraph(AgentState)\n\ngraph.add_node(\"collector\", data_collector_agent)\ngraph.add_node(\"extractor\", info_extractor_agent)\ngraph.add_node(\"generator\", alert_generator_agent)\ngraph.add_node(\"sender\", alert_sender_agent)\n\ngraph.add_edge(\"collector\", \"extractor\")\ngraph.add_edge(\"extractor\", \"generator\")\ngraph.add_edge(\"generator\", \"sender\")\ngraph.add_edge(\"sender\", END)\n\n# Checkpointer for long-running / resumable sessions\ncheckpointer = SqliteSaver.from_conn_string(\":memory:\")  # use a file path for persistence\napp = graph.compile(checkpointer=checkpointer)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Session Runner + Evaluation\n# Handles full execution for a user query.\n# Includes metrics, tracing, and error reporting.\ndef run_agent_session(query: str, thread_id: str = \"default\") -> AgentState:\n    start_time = time.time()\n    logger.info(f\"Session {thread_id}: starting for query='{query}'.\")\n    trace(\"SessionStart\", {\"thread_id\": thread_id, \"query\": query})\n    try:\n        config = {\"configurable\": {\"thread_id\": thread_id}}\n        state: AgentState = {\"query\": query, \"logs\": []}\n        result: AgentState = app.invoke(state, config=config)\n\n        metrics[\"executions\"] += 1\n        elapsed = time.time() - start_time\n        metrics[\"avg_time\"] = (\n            metrics[\"avg_time\"] * (metrics[\"executions\"] - 1) + elapsed\n        ) / metrics[\"executions\"]\n        logger.info(f\"Session {thread_id} completed in {elapsed:.2f}s. Metrics: {metrics}\")\n        trace(\"SessionComplete\", {\"thread_id\": thread_id, \"elapsed\": elapsed})\n        return result\n    except Exception as e:\n        metrics[\"errors\"] += 1\n        logger.error(f\"Error in session {thread_id}: {e}\", exc_info=True)\n        trace(\"SessionError\", {\"thread_id\": thread_id, \"error\": str(e)})\n        raise\n\n\ndef evaluate_agent() -> bool:\n    \"\"\"Simple evaluation: check if certain keys appear in the alert.\"\"\"\n    test_query = \"recent earthquakes and floods\"\n    expected_keys = [\"type\", \"location\", \"severity\"]\n    logger.info(\"Running evaluation with test query.\")\n    result = run_agent_session(test_query, thread_id=\"eval\")\n    alert = result.get(\"alert_message\", \"\").lower()\n    score = sum(1 for key in expected_keys if key in alert)\n    logger.info(f\"Evaluation score: {score}/{len(expected_keys)}\")\n\n    # Inspect past earthquake alerts\n    past_eq = retrieve_from_memory_bank(\"earthquake\")\n    logger.info(f\"Past earthquake alerts stored: {len(past_eq)}\")\n    trace(\"EvaluationResult\", {\"score\": score, \"expected\": len(expected_keys)})\n    return score == len(expected_keys)\n\n\ndef monitoring_loop(query: str, interval: int = 3600) -> None:\n    \"\"\"Long-running loop to periodically monitor disasters.\"\"\"\n    thread_id = \"monitor\"\n    logger.info(f\"Starting monitoring loop every {interval}s for query='{query}'.\")\n    while True:\n        run_agent_session(query, thread_id=thread_id)\n        time.sleep(interval)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example Usage (CLI demo)\nif __name__ == \"__main__\":\n    print(\"== Disaster Information Extraction & Alert Agent ==\")\n    result = run_agent_session(\"recent earthquakes and floods\", thread_id=\"demo\")\n    print(\"Generated Alert:\\n\", result.get(\"alert_message\", \"N/A\"))\n    print(\"\\nSession Logs:\")\n    for log in result.get(\"logs\", []):\n        print(\" -\", log)\n\n    ok = evaluate_agent()\n    print(\"\\nEvaluation passed:\", ok)\n    print(\"\\nMetrics:\", metrics)\n    print(\"\\nTrace log length:\", len(trace_log))\n    # For real deployment, call monitoring_loop() from a scheduler (e.g., Cloud Scheduler / cron).","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The Disaster Information Extraction & Alert Agent is a powerful demonstration of how multi-agent AI, real-time web data, and LLM intelligence can be combined to create an automated, high-impact disaster awareness system. Its blend of data collection, structured extraction, alert refinement, memory storage, and continuous monitoring showcases a practical, real-world application of AI for public safety.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}